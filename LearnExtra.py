import os

from keras.callbacks import History

os.environ['KMP_DUPLICATE_LIB_OK']='True'

from keras.models import Model, Sequential
from keras.layers import Input
from keras.layers import Flatten, Concatenate
from keras.layers.advanced_activations import LeakyReLU
from keras.layers import Dense, Dropout
from keras.preprocessing.image import ImageDataGenerator

x1 = Input(shape=(1,28,28))
x2 = Dense(32)(x1)
x2 = Flatten()(x1)
x2 = Flatten()(x1)
x2 = Dense(200)(x2)
x2 = Flatten()(x1)
x1 = Flatten()(x1)
x2 = Dense(200)(x2)
x3 = Concatenate()([x1,x2])
x4 = Dense(100)(x3)
out = Dense(10,activation='softmax')(x4)
inp = Input(shape=(1,28,28))
x1 = Flatten()(inp)
x1 = Flatten()(inp)
x2 = Dense(200)(x1)
x3 = Concatenate()([x1,x2])
x4 = Dense(100)(x3)
x5 = Concatenate([x2,x4])
x5 = Concatenate()([x2,x4])
out = Dense(10,activation='softmax')(x5)
model6 = Model(inputs=inp,outputs=out)
model6.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
model6.fit_generator(datagen.flow(x_train,y_train,batch_size=3000),validation_data=(x_test,y_test),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
inp = Input(shape=(1,28,28))
x1 = Flatten()(inp)
x11 = Dropout(0.4)(x1)
x1o = LeakyReLU(alpha=0.1)(x11)
x2 = Dense(200)(x1o)
x2o = LeakyReLU(alpha=0.1)(x2)
x3 = Concatenate()([x1,x2])
x3o = LeakyReLU(alpha=0.1)(x3)
x3 = Concatenate()([x1o,x2o])
x3o = LeakyReLU(alpha=0.1)(x3)
x4 = Dense(100)(x3o)
x2 = Dense(500)(x1o)
x4 = Dense(290)(x3o)
x4o = LeakyReLU(alpha=0.1)(x4)
x5 = Concatenate()([x2o,x4o])
x5o = LeakyReLU(alpha=0.1)(x5)
out = Dense(10,activation='softmax')(x5o)
model6 = Model(inputs=inp,outputs=out)
model6.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
model6.fit_generator(datagen.flow(x_train,y_train,batch_size=3000),validation_data=(x_test,y_test),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
inp = Input(shape=(1,28,28))
x1 = Flatten()(inp)
x11 = Dropout(0.4)(x1)
x1o = LeakyReLU(alpha=0.1)(x11)
x2 = Dense(500)(x1o)
x2o = LeakyReLU(alpha=0.1)(x2)
x3 = Dense(290)(x2o)
x4 = Concatenate()([x2,x3])
x4o = LeakyReLU(alpha=0.1)(x4)
out = Dense(10,activation='softmax')(x4o)
model6 = Model(inputs=inp,outputs=out)
model6.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
model6.fit_generator(datagen.flow(x_train,y_train,batch_size=3000),validation_data=(x_test,y_test),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
x2 = Dense(300)(x1o)
x3 = Dense(190)(x2o)
x2x3 = Concatenate()([x2,x3])
x3o = LeakyReLU(alpha=0.1)(x3)
x4 = Dense(100)(x3o)
x2x3o = LeakyReLU(alpha=0.1)(x2x3)
x4o = LeakyReLU(alpha=0.1)(x4)
out = Dense(10,activation='softmax')(x4o)
out1 = Dense(10,activation='softmax')(x4o)
out2 = Dense(10,activation='softmax')(x3o)
model7 = Model(inputs=inp,outputs=[out1,out2])
model7.compile(optimizer='adam', loss='categorical_crossentropy',loss_weights=[1.0,0.1],metrics=['accuracy'])
model7.fit_generator(datagen.flow(x_train,[y_train,y_train],batch_size=3000),validation_data=(x_test,[y_test,y_test]),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
model7.fit_generator(datagen.flow(x_train,y_train,batch_size=3000),validation_data=(x_test,y_test),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
model7.fit_generator(datagen.flow(x_train,[y_train,y_train],batch_size=3000),validation_data=(x_test,[y_test,y_test]),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
model7.fit_generator(datagen.flow([x_train],[y_train,y_train],batch_size=3000),validation_data=([x_test],[y_test,y_test]),steps_per_epoch=20,epochs=10000, callbacks=[calbak])
datagen
datagen = ImageDataGenerator(rotation_range=15,height_shift_range=3,width_shift_range=3,data_format='channels_first')
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=60000)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=600000)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=60000)
td1 = datagen.flow(x_train,y_train,batch_size=600000)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=60000)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=6000)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=600)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=60)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=6)
(x_t1, y_t1) = datagen.flow(x_train,y_train,batch_size=6000)
x_t1, y_t1 = datagen.flow(x_train,y_train,batch_size=6000)
datagen.flow(x_train,y_train,batch_size=6000)
(x_t1, y_t1) = list(datagen.flow(x_train,y_train,batch_size=6000))
